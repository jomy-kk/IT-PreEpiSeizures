{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:22:55.708629Z",
     "start_time": "2024-10-10T11:22:52.590013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import timedelta\n",
    "from glob import glob\n",
    "from os import mkdir, remove\n",
    "from os.path import join, exists\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ltbio.biosignals.modalities import EEG\n",
    "from ltbio.biosignals.timeseries import Timeline\n",
    "from ltbio.processing.formaters import Segmenter"
   ],
   "id": "87196f9773b9c756",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-10T11:22:55.784928Z",
     "start_time": "2024-10-10T11:22:55.711845Z"
    }
   },
   "source": [
    "common_path = \"/Volumes/MMIS-Saraiv/Datasets/Sapienza/denoised_biosignal/\"\n",
    "out_common_path = \"/Volumes/MMIS-Saraiv/Datasets/Sapienza/denoised_txt_epochs/\"\n",
    "all_files = glob(join(common_path, \"*.biosignal\"))"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:22:55.791260Z",
     "start_time": "2024-10-10T11:22:55.786140Z"
    }
   },
   "cell_type": "code",
   "source": "channel_order = ('C3', 'C4', 'Cz', 'F3', 'F4', 'F7', 'F8', 'Fp1', 'Fp2', 'Fpz', 'Fz', 'O1', 'O2', 'P3', 'P4', 'Pz', 'T3', 'T4', 'T5', 'T6')  # without mastoids",
   "id": "160216cb80b8f1e2",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:27:37.547612Z",
     "start_time": "2024-10-10T11:22:55.793568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for filepath in all_files:\n",
    "    filename = filepath.split('/')[-1].split('.')[0]\n",
    "    print(filename)\n",
    "    subject_out_path = join(out_common_path, filename)\n",
    "    if not exists(subject_out_path):\n",
    "        mkdir(subject_out_path)\n",
    "    # Load Biosignal\n",
    "    x = EEG.load(filepath)\n",
    "    x = x[channel_order]  # get only channels of interest\n",
    "\n",
    "    # Get only signal with quality\n",
    "    good = Timeline.load(join(common_path, filename + '_good.timeline'))\n",
    "    x = x[good]\n",
    "    \n",
    "    # Epochs\n",
    "    print(\"Segmenting...\")\n",
    "    segmenter = Segmenter(timedelta(seconds=2))\n",
    "    segmented_x = segmenter(x)\n",
    "    print(\"Segmented\")\n",
    "    \n",
    "    # Go by segment\n",
    "    intervals = segmented_x['O2'].domain\n",
    "    for i, interval in enumerate(intervals):\n",
    "        print(f\"Segment {i}\")\n",
    "        segment = segmented_x[interval]\n",
    "        _array: np.ndarray = segment.to_array(channel_order).T\n",
    "        # Make a txt in ASCII format, and put the array data there; write with maximum 4 decimal places\n",
    "        with open(join(subject_out_path, f\"{filename}_{i}.txt\"), 'w', encoding='ascii') as f:\n",
    "            np.savetxt(f, _array, fmt='%.4f', delimiter='\\t')\n",
    "         "
   ],
   "id": "d8563a50f2d656f3",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "37f987006f4f04e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:39:47.357267Z",
     "start_time": "2024-10-10T10:39:47.255291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_common_path = \"/Volumes/MMIS-Saraiv/Datasets/Sapienza/roma_protocol_source/\"\n",
    "all_participant_txt_directories = glob(join(out_common_path, \"PARTICIPANT*\"))\n",
    "for directory in all_participant_txt_directories:\n",
    "    all_txt_files = glob(join(directory, \"*.txt\"))\n",
    "    sub_filename = directory.split('/')[-1]\n",
    "    all_epoch_numbers = [int(file.split('/')[-1].split('_')[-1].split('.')[0]) for file in all_txt_files]\n",
    "    all_epoch_numbers.sort()\n",
    "    # delete last file\n",
    "    last_epoch_number = all_epoch_numbers[-1]\n",
    "    last_file = join(directory, f\"{sub_filename}_{last_epoch_number}.txt\")\n",
    "    print(last_file)\n",
    "    remove(last_file)"
   ],
   "id": "919acb7eaaf622f9",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:16:08.461834Z",
     "start_time": "2024-10-10T10:15:58.520152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_common_path = \"/Volumes/MMIS-Saraiv/Datasets/Sapienza/roma_protocol_source\"\n",
    "all_participant_txt_directories = glob(join(out_common_path, \"PARTICIPANT*\"))\n",
    "for directory in all_participant_txt_directories:\n",
    "    all_txt_files = glob(join(directory, \"*.txt\"))\n",
    "    for file in all_txt_files:\n",
    "        # read with numpy\n",
    "        data = np.loadtxt(file, delimiter='\\t')\n",
    "        # are there nans?\n",
    "        if np.isnan(data).any():\n",
    "            print(file)\n",
    "            #remove(file)"
   ],
   "id": "9a739dd9ef8fa907",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "bd7cb3bc56abf436",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
