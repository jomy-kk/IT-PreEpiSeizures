{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-30T15:13:52.431478Z",
     "start_time": "2024-05-30T15:13:52.424506Z"
    }
   },
   "source": [
    "from glob import glob\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "common_path = '/Volumes/MMIS-Saraiv/Datasets/Miltiadous Dataset/features'\n",
    "all_directories = glob(join(common_path, '*'))\n",
    "all_directories = [directory for directory in all_directories if not directory.endswith('.csv')]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T14:33:40.463352Z",
     "start_time": "2024-05-30T14:33:40.458827Z"
    }
   },
   "id": "bc4f10c251948d64",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "FEATURES_SELECTED = ['Spectral#RelativePower#C3#beta1', 'Spectral#EdgeFrequency#C3#beta3', 'Spectral#RelativePower#C3#gamma', 'Spectral#EdgeFrequency#C4#alpha1', 'Spectral#RelativePower#C4#beta3', 'Spectral#EdgeFrequency#C4#beta3', 'Spectral#EdgeFrequency#C4#gamma', 'Spectral#Flatness#Cz#theta', 'Spectral#PeakFrequency#Cz#theta', 'Spectral#EdgeFrequency#Cz#beta3', 'Spectral#EdgeFrequency#Cz#gamma', 'Spectral#PeakFrequency#Cz#gamma', 'Spectral#RelativePower#F3#beta1', 'Spectral#Diff#F4#delta', 'Spectral#RelativePower#F7#beta3', 'Spectral#EdgeFrequency#F7#beta3', 'Spectral#RelativePower#F7#gamma', 'Spectral#RelativePower#F8#beta1', 'Spectral#EdgeFrequency#F8#beta3', 'Spectral#RelativePower#Fp1#beta1', 'Spectral#EdgeFrequency#Fp1#beta3', 'Spectral#Diff#Fp2#delta', 'Spectral#RelativePower#Fp2#beta1', 'Spectral#RelativePower#Fp2#beta3', 'Spectral#Diff#Fpz#beta2', 'Spectral#Entropy#O1#delta', 'Spectral#RelativePower#O1#beta2', 'Spectral#EdgeFrequency#O1#beta2', 'Spectral#EdgeFrequency#O1#beta3', 'Spectral#RelativePower#O2#delta', 'Spectral#PeakFrequency#O2#alpha1', 'Spectral#RelativePower#O2#beta1', 'Spectral#RelativePower#O2#beta3', 'Spectral#Diff#P3#beta1', 'Spectral#RelativePower#P3#beta3', 'Spectral#RelativePower#Pz#alpha1', 'Spectral#EdgeFrequency#Pz#beta3', 'Spectral#RelativePower#T4#alpha1', 'Spectral#RelativePower#T4#beta3', 'Spectral#RelativePower#T4#gamma', 'Spectral#EdgeFrequency#T5#beta2', 'Hjorth#Complexity#T5', 'Hjorth#Complexity#P4', 'Hjorth#Complexity#F7', 'Hjorth#Complexity#T4', 'Hjorth#Complexity#F8', 'Hjorth#Complexity#T3', 'Hjorth#Mobility#P3', 'PLI#Frontal(L)-Temporal(R)#alpha1', 'PLI#Frontal(L)-Occipital(L)#alpha1', 'PLI#Frontal(R)-Temporal(R)#alpha1', 'PLI#Temporal(R)-Parietal(R)#alpha1', 'PLI#Temporal(R)-Occipital(L)#alpha1', 'PLI#Parietal(R)-Occipital(L)#alpha1', 'PLI#Occipital(L)-Occipital(R)#alpha1', 'PLI#Temporal(R)-Occipital(R)#alpha2', 'PLI#Parietal(R)-Occipital(L)#alpha2', 'COH#Frontal(L)-Frontal(R)#theta', 'COH#Frontal(L)-Occipital(L)#theta', 'COH#Frontal(L)-Occipital(R)#alpha1', 'COH#Frontal(R)-Occipital(L)#alpha1', 'COH#Parietal(R)-Occipital(L)#alpha1', 'COH#Frontal(L)-Frontal(R)#alpha2', 'COH#Frontal(L)-Occipital(R)#alpha2', 'COH#Parietal(R)-Occipital(L)#alpha2', 'COH#Parietal(R)-Occipital(R)#alpha2', 'COH#Occipital(L)-Occipital(R)#alpha2', 'COH#Frontal(L)-Occipital(L)#beta1', 'COH#Temporal(R)-Parietal(R)#beta1', 'COH#Parietal(R)-Occipital(R)#beta1', 'COH#Frontal(L)-Parietal(L)#beta2', 'COH#Frontal(R)-Occipital(L)#beta2', 'COH#Frontal(L)-Temporal(R)#beta3', 'COH#Frontal(L)-Parietal(L)#beta3', 'COH#Frontal(L)-Occipital(L)#beta3', 'COH#Frontal(L)-Occipital(R)#beta3', 'COH#Frontal(R)-Occipital(L)#beta3', 'COH#Temporal(L)-Occipital(R)#beta3', 'COH#Frontal(L)-Occipital(R)#gamma', 'COH#Frontal(R)-Occipital(R)#gamma']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T14:33:40.956121Z",
     "start_time": "2024-05-30T14:33:40.952635Z"
    }
   },
   "id": "4cca7eabc6f58643",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "for subject_path in all_directories:\n",
    "    all_multiple_files = glob(join(subject_path, '*$Multiple.csv'))\n",
    "    if len(all_multiple_files) != 0:  # underrepresented target\n",
    "        print(\"##################\")\n",
    "        print(\"Subject: \", subject_path.split('/')[-1])\n",
    "        # Read them all\n",
    "        all_data = [pd.read_csv(file, index_col=0) for file in all_multiple_files]\n",
    "        # Concatenate all their columns in a single DataFrame\n",
    "        all_data = pd.concat(all_data, axis=1)\n",
    "        # Keep only selected features\n",
    "        FEATURES_SELECTED = [col for col in all_data.columns if col in FEATURES_SELECTED]\n",
    "        selected_features = all_data[FEATURES_SELECTED]\n",
    "        # drop nans\n",
    "        selected_features = selected_features.dropna()\n",
    "        \n",
    "        # Normalise each row between 0 and 1\n",
    "        # Normalise each feature (column) between 0 and 1\n",
    "        selected_features = (selected_features - selected_features.min()) / (selected_features.max() - selected_features.min())\n",
    "\n",
    "        # DISTORTION / AUGMENTATION\n",
    "        # Apply noise to each row\n",
    "        # Apply noise to each row\n",
    "        \"\"\"\n",
    "        for row in range(len(selected_features)):\n",
    "            data = selected_features.iloc[row].values\n",
    "            data = data + np.random.normal(loc=0, scale=0.2, size=data.shape)\n",
    "            selected_features.iloc[row] = data\n",
    "        \"\"\"\n",
    "        \n",
    "        # Normalise across all rows (examples)\n",
    "        selected_features = (selected_features - selected_features.min()) / (selected_features.max() - selected_features.min())\n",
    "        \n",
    "        # STATISTICAL TESTS\n",
    "        independent_rows = []\n",
    "        dependent_rows = []\n",
    "        from scipy.stats import mannwhitneyu\n",
    "        for i in range(len(selected_features)):\n",
    "            for j in range(i, len(selected_features)):\n",
    "                # Perform <Mann-Whitney U test>\n",
    "                u_stat, p = mannwhitneyu(selected_features.iloc[i], selected_features.iloc[j])\n",
    "                # interpret\n",
    "                # p > alpha: Likely come from the same distribution (fail to reject H0)\n",
    "                # p <= alpha: Likely come from different distributions (reject H0)\n",
    "                alpha = 0.05\n",
    "                # print the p-values with 3 decimal places\n",
    "                if p > alpha:\n",
    "                    #print(f'Rows ({i}, {j}): Likely come from the same subject (fail to reject H0). u_stat={u_stat}, p={p:.3f}')\n",
    "                    if i != j:\n",
    "                        dependent_rows.append((i, j))\n",
    "                else:\n",
    "                    #print(f'Rows ({i}, {j}): Likely come from different subjects (reject H0) u_stat={u_stat}, p={p:.3f}')\n",
    "                    independent_rows.append((i, j))\n",
    "        \n",
    "        print(\"Number of independent pairs:\", len(independent_rows))\n",
    "        \n",
    "        #print(\"##################\")\n",
    "        import networkx as nx\n",
    "        G = nx.Graph()\n",
    "        # Add a node for each row\n",
    "        for i in range(len(selected_features)):\n",
    "            G.add_node(i)\n",
    "        # Add an edge for each pair with p-value less than 0.05\n",
    "        for i, j in independent_rows:\n",
    "            G.add_edge(i, j)\n",
    "        # Find the largest clique\n",
    "        cliques = list(nx.find_cliques(G))\n",
    "        #print(\"All cliques:\")\n",
    "        #for clique in cliques:\n",
    "        #    print(clique)\n",
    "        largest_clique = max(cliques, key=len)\n",
    "        #print(\"The largest set of rows where all pairs have p<0.05 is:\")\n",
    "        #print(largest_clique)\n",
    "        K = len(largest_clique)\n",
    "        print(f'Length of the largest clique, {K}, will be K.')\n",
    "        \n",
    "        # Use a clustering algorithm\n",
    "        K = len(largest_clique)\n",
    "        kmeans = KMeans(n_clusters=K, random_state=0).fit(selected_features)\n",
    "        labels = kmeans.labels_\n",
    "        #print(f'Cluster labels: {labels}')\n",
    "        \n",
    "        # Check if any of the independent pairs are in the same cluster\n",
    "        to_exclude = []\n",
    "        for i, j in independent_rows:\n",
    "            if labels[i] == labels[j]:\n",
    "                #print(f'Rows ({i}, {j}) are independent but in the same cluster')\n",
    "                to_exclude.append((i, j))\n",
    "        \n",
    "        \n",
    "        print(\"Independent pairs that can be safely used because they're not clustered together:\")\n",
    "        safe_pairs = []\n",
    "        for i, j in independent_rows:\n",
    "            if (i, j) not in to_exclude and (j, i) not in to_exclude:\n",
    "                safe_pairs.append((i, j))\n",
    "                print(f'Pair ({i}, {j})')\n",
    "                \n",
    "        cliques_K = [clique for clique in cliques if len(clique) == K]\n",
    "        print(f\"Cliques with {K} elements with safe pairs to use:\")\n",
    "        for clique in cliques_K:\n",
    "            if all((i, j) in safe_pairs or (j, i) in safe_pairs for i in clique for j in clique if i != j):\n",
    "                print(clique)\n",
    "        \n",
    "        #break\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T18:20:06.403300Z",
     "start_time": "2024-05-30T18:20:05.786914Z"
    }
   },
   "id": "c4ac6e50a86d251f",
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "36ad351fdcbf8c46",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
